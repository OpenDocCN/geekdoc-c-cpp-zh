["```cpp\ncommit 9a13c1c6971f4bd56d143179ecfb34cca8ecc018\nAuthor: Steinar H. Gunderson <steinar.gunderson@oracle.com>\nDate:   Tue Jun 8 15:14:35 2021 +0200\n\n    Bug #32976857: REMOVE QEP_TAB_STANDALONE [range optimizer, noclose]\n\n    Remove the QEP_TAB dependency from test_quick_select() (ie., the range\n    optimizer).\n\n    Change-Id: Ie0fcce71dfc813920711c43c3d62635dae0d7d20 \n```", "```cpp\nstatic SEL_TREE *get_full_func_mm_tree(THD *thd, RANGE_OPT_PARAM *param,\n                                       table_map prev_tables,\n                                       table_map read_tables,\n                                       table_map current_table,\n                                       bool remove_jump_scans, Item *predicand,\n                                       Item_func *op, Item *value, bool inv) {\n  SEL_TREE *tree = nullptr;\n  SEL_TREE *ftree = nullptr;\n  const table_map param_comp = ~(prev_tables | read_tables | current_table);\n  DBUG_TRACE;\n  ... \n```", "```cpp\n /*\n    If the queue was not empty, we're a follower and wait for the\n    leader to process the queue. If we were holding a mutex, we have\n    to release it before going to sleep.\n  */\n  if (!leader) {\n    CONDITIONAL_SYNC_POINT_FOR_TIMESTAMP(\"before_follower_wait\");\n    mysql_mutex_lock(&m_lock_done);\n    ... \n    ulonglong start_wait_time = my_micro_time();\n    while (thd->tx_commit_pending) {\n      if (stage == COMMIT_ORDER_FLUSH_STAGE) {\n        mysql_cond_wait(&m_stage_cond_commit_order, &m_lock_done);\n      } else {\n        mysql_cond_wait(&m_stage_cond_binlog, &m_lock_done);\n      }\n    }\n    ulonglong end_wait_time = my_micro_time();\n    ulonglong wait_time = end_wait_time - start_wait_time;\n    if (wait_time > 100000) {\n        fprintf(stderr, \"wait too long:%llu\\n\", wait_time);\n    }\n    mysql_mutex_unlock(&m_lock_done);\n    return false;\n  } \n```", "```cpp\n /*\n    If the queue was not empty, we're a follower and wait for the\n    leader to process the queue. If we were holding a mutex, we have\n    to release it before going to sleep.\n  */\n  if (!leader) {\n    CONDITIONAL_SYNC_POINT_FOR_TIMESTAMP(\"before_follower_wait\");\n    mysql_mutex_lock(&m_lock_done);\n    ...\n    ulonglong start_wait_time = my_micro_time();\n    while (thd->tx_commit_pending) {\n      if (stage == COMMIT_ORDER_FLUSH_STAGE) {\n        mysql_cond_wait(&m_stage_cond_commit_order, &m_lock_done);\n      } else {\n        mysql_cond_wait(&m_stage_cond_binlog, &m_lock_done);\n      }\n      fprintf(stderr, \"wake up thread:%p,total wait time:%llu, stage:%d\\n\",\n              thd, my_micro_time() - start_wait_time, stage);\n    }\n    ulonglong end_wait_time = my_micro_time();\n    ulonglong wait_time = end_wait_time - start_wait_time;\n    if (wait_time > 100000) {\n        fprintf(stderr, \"wait too long:%llu for thread:%p\\n\", wait_time, thd);\n    }\n    mysql_mutex_unlock(&m_lock_done);\n    return false;\n  } \n```", "```cpp\nvoid Commit_stage_manager::signal_done(THD *queue, StageID stage) {\n  mysql_mutex_lock(&m_lock_done);\n  for (THD *thd = queue; thd; thd = thd->next_to_commit) {\n    thd->tx_commit_pending = false;\n    thd->rpl_thd_ctx.binlog_group_commit_ctx().reset();\n  }\n  /* if thread belong to commit order wake only commit order queue threads */\n  if (stage == COMMIT_ORDER_FLUSH_STAGE)\n    mysql_cond_broadcast(&m_stage_cond_commit_order);\n  else\n    mysql_cond_broadcast(&m_stage_cond_binlog);\n  mysql_mutex_unlock(&m_lock_done);\n} \n```", "```cpp\nprivate:\n  // Disable copying\n  ReadView(const ReadView &);\n  ReadView &operator=(const ReadView &);\nprivate:\n  /** The read should not see any transaction with trx id >= this\n  value. In other words, this is the \"high water mark\". */\n  trx_id_t m_low_limit_id;\n  /** The read should see all trx ids which are strictly\n  smaller (<) than this value.  In other words, this is the\n  low water mark\". */\n  trx_id_t m_up_limit_id;\n  /** trx id of creating transaction, set to TRX_ID_MAX for free\n  views. */\n  trx_id_t m_creator_trx_id;\n  /** Set of RW transactions that was active when this snapshot\n  was taken */\n  ids_t m_ids;\n  /** The view does not need to see the undo logs for transactions\n  whose transaction number is strictly smaller (<) than this value:\n  they can be removed in purge if not needed by other views */\n  trx_id_t m_low_limit_no;\n  ... \n```", "```cpp\n /** This is similar to a std::vector but it is not a drop\n  in replacement. It is specific to ReadView. */\n  class ids_t {\n    typedef trx_ids_t::value_type;\n    /**\n    Constructor */\n    ids_t() : m_ptr(), m_size(), m_reserved() {}\n    /**\n    Destructor */\n    ~ids_t() { ut::delete_arr(m_ptr); }\n    /** Try and increase the size of the array. Old elements are copied across.\n    It is a no-op if n is < current size.\n    @param n            Make space for n elements */\n    void reserve(ulint n);\n    ... \n```", "```cpp\n /** Check whether the changes by id are visible.\n  @param[in]    id      transaction id to check against the view\n  @param[in]    name    table name\n  @return whether the view sees the modifications of id. */\n  [[nodiscard]] bool changes_visible(trx_id_t id,\n                                     const table_name_t &name) const {\n    ut_ad(id > 0);\n    if (id < m_up_limit_id || id == m_creator_trx_id) {\n      return (true);\n    }\n    check_trx_id_sanity(id, name);\n    if (id >= m_low_limit_id) {\n      return (false);\n    } else if (m_ids.empty()) {\n      return (true);\n    }\n    const ids_t::value_type *p = m_ids.data();\n    return (!std::binary_search(p, p + m_ids.size(), id));\n } \n```", "```cpp\nclass ReadView {\n ...\n private:\n  // Disable copying\n  ReadView &operator=(const ReadView &);\n public:\n  bool skip_view_list{false};\n private:\n  unsigned char top_active[MAX_TOP_ACTIVE_BYTES];\n  trx_id_t m_short_min_id;\n  trx_id_t m_short_max_id;\n  bool m_has_short_actives;\n  /** The read should not see any transaction with trx id >= this\n  value. In other words, this is the \"high water mark\". */\n  trx_id_t m_low_limit_id;\n  /** The read should see all trx ids which are strictly\n  smaller (<) than this value.  In other words, this is the low water mark\". */\n  trx_id_t m_up_limit_id;\n  /** trx id of creating transaction, set to TRX_ID_MAX for free views. */\n  trx_id_t m_creator_trx_id;\n  /** Set of RW transactions that was active when this snapshot\n  was taken */\n  ids_t m_long_ids;\n  ... \n```", "```cpp\n /** Array of Read write transaction IDs for MVCC snapshot. A ReadView would\n  take a snapshot of these transactions whose changes are not visible to it.\n  We should remove transactions from the list before committing in memory and\n  releasing locks to ensure right order of removal and consistent snapshot. */\n  trx_ids_t rw_trx_ids; \n```", "```cpp\n /** Array of Read write transaction IDs for MVCC snapshot. A ReadView would\n  take a snapshot of these transactions whose changes are not visible to it.\n  We should remove transactions from the list before committing in memory and\n  releasing locks to ensure right order of removal and consistent snapshot. */\n  trx_ids_t long_rw_trx_ids;\n  unsigned char short_rw_trx_ids_bitmap[MAX_SHORT_ACTIVE_BYTES];\n  int short_rw_trx_valid_number;\n  trx_id_t min_short_valid_id;\n  trx_id_t max_short_valid_id \n```", "```cpp\n } else if (trx->isolation_level <= TRX_ISO_READ_COMMITTED &&\n               MVCC::is_view_active(trx->read_view)) {\n      mutex_enter(&trx_sys->mutex);\n      trx_sys->mvcc->view_close(trx->read_view, true);\n      mutex_exit(&trx_sys->mutex);\n    } \n```", "```cpp\n if (lock_type != TL_IGNORE && trx->n_mysql_tables_in_use == 0) {\n    trx->isolation_level =\n        innobase_trx_map_isolation_level(thd_get_trx_isolation(thd));\n    if (trx->isolation_level <= TRX_ISO_READ_COMMITTED &&\n        MVCC::is_view_active(trx->read_view)) {\n      /* At low transaction isolation levels we let\n      each consistent read set its own snapshot */\n      mutex_enter(&trx_sys->mutex);\n      trx_sys->mvcc->view_close(trx->read_view, true);\n      mutex_exit(&trx_sys->mutex);\n    }\n  } \n```", "```cpp\n } else if (trx->isolation_level <= TRX_ISO_READ_COMMITTED &&\n               MVCC::is_view_active(trx->read_view)) {\n      trx_sys->mvcc->view_close(trx->read_view, false);\n} \n```", "```cpp\n if (lock_type != TL_IGNORE && trx->n_mysql_tables_in_use == 0) {\n    trx->isolation_level =\n        innobase_trx_map_isolation_level(thd_get_trx_isolation(thd));\n    if (trx->isolation_level <= TRX_ISO_READ_COMMITTED &&\n        MVCC::is_view_active(trx->read_view)) {\n      /* At low transaction isolation levels we let\n      each consistent read set its own snapshot */\n      trx_sys->mvcc->view_close(trx->read_view, false);\n    }\n  } \n```", "```cpp\nbool PT_insert_values_list::contextualize(Parse_context *pc) {\n  if (super::contextualize(pc)) return true;\n  for (List_item *item_list : many_values) {\n    for (auto it = item_list->begin(); it != item_list->end(); ++it) {\n      if ((*it)->itemize(pc, &*it)) return true;\n    }\n  }\n\n  return false;\n} \n```", "```cpp\nbool PT_insert_values_list::contextualize(Parse_context *pc)\n{\n  if (super::contextualize(pc))\n    return true;\n  List_iterator<List_item> it1(many_values);\n  List<Item> *item_list;\n  while ((item_list= it1++))\n  {\n    List_iterator<Item> it2(*item_list);\n    Item *item;\n    while ((item= it2++))\n    {\n      if (item->itemize(pc, &item))\n        return true;\n      it2.replace(item);\n    }\n  }\n\n  return false;\n} \n```", "```cpp\nstd::deque (double-ended queue) is an indexed sequence container that allows fast insertion and deletion at both its \nbeginning and its end. In addition, insertion and deletion at either end of a deque never invalidates pointers or \nreferences to the rest of the elements.\n\nAs opposed to std::vector, the elements of a deque are not stored contiguously: typical implementations use a sequence \nof individually allocated fixed-size arrays, with additional bookkeeping, which means indexed access to deque must \nperform two pointer dereferences, compared to vector's indexed access which performs only one.\n\nThe storage of a deque is automatically expanded and contracted as needed. Expansion of a deque is cheaper than the \nexpansion of a std::vector because it does not involve copying of the existing elements to a new memory location. On \nthe other hand, deques typically have large minimal memory cost; a deque holding just one element has to allocate its \nfull internal array (e.g. 8 times the object size on 64-bit libstdc++; 16 times the object size or 4096 bytes, \nwhichever is larger, on 64-bit libc++).\n\nThe complexity (efficiency) of common operations on deques is as follows:\nRandom access - constant O(1).\nInsertion or removal of elements at the end or beginning - constant O(1).\nInsertion or removal of elements - linear O(n). \n```", "```cpp\nThe implementation is the same as classic std::deque: Elements are held in blocks of about 1 kB each. \n```", "```cpp\n/** Write the redo log record, add dirty pages to the flush list and \nrelease the resources. */\nvoid mtr_t::Command::execute()\n{\n  ut_ad(m_impl->m_log_mode != MTR_LOG_NONE);\n  if (const ulint len = prepare_write()) {\n    finish_write(len);\n  }\n  if (m_impl->m_made_dirty) {\n    log_flush_order_mutex_enter();\n  }\n  /* It is now safe to release the log mutex because the\n  flush_order mutex will ensure that we are the first one\n  to insert into the flush list. */\n  log_mutex_exit();\n  m_impl->m_mtr->m_commit_lsn = m_end_lsn;\n  release_blocks();\n  if (m_impl->m_made_dirty) {\n    log_flush_order_mutex_exit();\n  }\n  release_all();\n  release_resources();\n} \n```", "```cpp\n/** Write the redo log record, add dirty pages to the flush list and \nrelease the resources. */\nvoid mtr_t::Command::execute() {\n  ut_ad(m_impl->m_log_mode != MTR_LOG_NONE);\n#ifndef UNIV_HOTBACKUP\n  ulint len = prepare_write();\n  if (len > 0) {\n    mtr_write_log_t write_log;\n    write_log.m_left_to_write = len;\n    auto handle = log_buffer_reserve(*log_sys, len);\n    write_log.m_handle = handle;\n    write_log.m_lsn = handle.start_lsn;\n    m_impl->m_log.for_each_block(write_log);\n    ut_ad(write_log.m_left_to_write == 0);\n    ut_ad(write_log.m_lsn == handle.end_lsn);\n    log_wait_for_space_in_log_recent_closed(*log_sys, handle.start_lsn);\n    DEBUG_SYNC_C(\"mtr_redo_before_add_dirty_blocks\");\n    add_dirty_blocks_to_flush_list(handle.start_lsn, handle.end_lsn);\n    log_buffer_close(*log_sys, handle);\n    m_impl->m_mtr->m_commit_lsn = handle.end_lsn;\n  } else {\n    DEBUG_SYNC_C(\"mtr_noredo_before_add_dirty_blocks\");\n    add_dirty_blocks_to_flush_list(0, 0);\n  }\n#endif /* !UNIV_HOTBACKUP */ \n```", "```cpp\n/******************************************************//**\nDetermine the offset to each field in a leaf-page record\nin ROW_FORMAT=COMPACT.  This is a special case of\nrec_init_offsets() and rec_get_offsets_func(). */\nUNIV_INLINE MY_ATTRIBUTE((nonnull))\nvoid\nrec_init_offsets_comp_ordinary(\n/*===========================*/\n  const rec_t*    rec,  /*!< in: physical record in\n          ROW_FORMAT=COMPACT */\n  bool      temp, /*!< in: whether to use the\n          format for temporary files in\n          index creation */\n  const dict_index_t* index,  /*!< in: record descriptor */\n  ulint*      offsets)/*!< in/out: array of offsets;\n          in: n=rec_offs_n_fields(offsets) */\n{   \n  ulint   i   = 0;\n  ulint   offs    = 0;\n  ulint   any_ext   = 0;\n  ulint   n_null    = index->n_nullable;\n  const byte* nulls   = temp\n    ? rec - 1\n    : rec - (1 + REC_N_NEW_EXTRA_BYTES);\n  const byte* lens    = nulls - UT_BITS_IN_BYTES(n_null);\n  ulint   null_mask = 1;\n\n  ...\n  ut_ad(temp || dict_table_is_comp(index->table));\n\n  if (temp && dict_table_is_comp(index->table)) {\n    /* No need to do adjust fixed_len=0\\. We only need to\n    adjust it for ROW_FORMAT=REDUNDANT. */\n    temp = false;\n  }\n  /* read the lengths of fields 0..n */\n  do {\n    const dict_field_t* field\n      = dict_index_get_nth_field(index, i);\n    const dict_col_t* col\n      = dict_field_get_col(field);\n    ulint     len;\n  ... \n```", "```cpp\n/** Determine the offset to each field in a leaf-page record in\nROW_FORMAT=COMPACT.  This is a special case of rec_init_offsets() and\nrec_get_offsets().\n...\n*/\ninline void rec_init_offsets_comp_ordinary(const rec_t *rec, bool temp,\n                                           const dict_index_t *index,\n                                           ulint *offsets) {\n  ...\n  const byte *nulls = nullptr;\n  const byte *lens = nullptr;\n  uint16_t n_null = 0;\n  enum REC_INSERT_STATE rec_insert_state = REC_INSERT_STATE::NONE;\n  uint8_t row_version = UINT8_UNDEFINED;\n  uint16_t non_default_fields = 0;\n\n  if (temp) {\n    rec_insert_state = rec_init_null_and_len_temp(\n        rec, index, &nulls, &lens, &n_null, non_default_fields, row_version);\n  } else {\n    rec_insert_state = rec_init_null_and_len_comp(\n        rec, index, &nulls, &lens, &n_null, non_default_fields, row_version);\n  }\n\n  ut_ad(temp || dict_table_is_comp(index->table));\n  if (temp) {\n    if (dict_table_is_comp(index->table)) {\n      /* No need to do adjust fixed_len=0\\. We only need to\n      adjust it for ROW_FORMAT=REDUNDANT. */\n      temp = false;\n    } else {\n      /* Redundant temp row. Old instant record is logged as version 0.*/\n      if (rec_insert_state == INSERTED_BEFORE_INSTANT_ADD_OLD_IMPLEMENTATION ||\n          rec_insert_state == INSERTED_AFTER_INSTANT_ADD_OLD_IMPLEMENTATION) {\n        rec_insert_state = INSERTED_BEFORE_INSTANT_ADD_NEW_IMPLEMENTATION;\n        ut_ad(row_version == UINT8_UNDEFINED);\n      }\n    }\n  }\n\n  /* read the lengths of fields 0..n */\n  ulint offs = 0;\n  ulint any_ext = 0;\n  ulint null_mask = 1;\n  uint16_t i = 0;\n  do {\n    /* Fields are stored on disk in version they are added in and are\n    maintained in fields_array in the same order. Get the right field. */\n    const dict_field_t *field = index->get_physical_field(i);\n    const dict_col_t *col = field->col;\n    uint64_t len;\n\n    switch (rec_insert_state) {\n      case INSERTED_INTO_TABLE_WITH_NO_INSTANT_NO_VERSION:\n        ut_ad(!index->has_instant_cols_or_row_versions());\n        break;\n\n      case INSERTED_BEFORE_INSTANT_ADD_NEW_IMPLEMENTATION: {\n        ut_ad(row_version == UINT8_UNDEFINED || row_version == 0);\n        ut_ad(index->has_row_versions() || temp);\n        /* Record has to be interpreted in v0\\. */\n        row_version = 0;\n      }\n        [[fallthrough]];\n      case INSERTED_AFTER_UPGRADE_BEFORE_INSTANT_ADD_NEW_IMPLEMENTATION\n      case INSERTED_AFTER_INSTANT_ADD_NEW_IMPLEMENTATION: {\n        ...\n      } break;\n      case INSERTED_BEFORE_INSTANT_ADD_OLD_IMPLEMENTATION:\n      case INSERTED_AFTER_INSTANT_ADD_OLD_IMPLEMENTATION: {\n        ...\n      } break;\n\n      default:\n        ut_ad(false);\n    }\n    ... \n```", "```cpp\nvoid validate_rec_offset(const dict_index_t *index, const ulint *offsets,\n                         ulint n, ut::Location L) {\n  ut_ad(rec_offs_validate(nullptr, nullptr, offsets));\n  if (n >= rec_offs_n_fields(offsets)) {\n#ifndef UNIV_NO_ERR_MSGS\n    dump_metadata_dict_table(index->table);\n    auto num_fields = static_cast<size_t>(rec_offs_n_fields(offsets));\n    ib::fatal(L, ER_IB_DICT_INVALID_COLUMN_POSITION, ulonglong{n}, num_fields);\n#endif /* !UNIV_NO_ERR_MSGS */   }\n} \n```", "```cpp\n// clang-format off\n/** Convert a field in the Innobase format to a field in the MySQL format.\n@param[out]     mysql_rec       Record in the MySQL format\n@param[in,out]  prebuilt        Prebuilt struct\n@param[in]      rec             InnoDB record; must be protected by a page\n                                latch\n@param[in]      rec_index       Index of rec\n@param[in]      prebuilt_index  prebuilt->index\n@param[in]      offsets         Array returned by rec_get_offsets()\n@param[in]      field_no        templ->rec_field_no or\n                                templ->clust_rec_field_no or\n                                templ->icp_rec_field_no or sec field no if\n                                clust_templ_for_sec is true\n@param[in]      templ           row template\n@param[in]      sec_field_no    Secondary index field no if the secondary index\n                                record but the prebuilt template is in\n                                clustered index format and used only for end\n                                range comparison.\n@param[in]      lob_undo        the LOB undo information.\n@param[in,out]  blob_heap       If not null then use this heap for BLOBs */\n// clang-format on\n[[nodiscard]] static bool row_sel_store_mysql_field(\n    byte *mysql_rec, row_prebuilt_t *prebuilt, const rec_t *rec,\n    const dict_index_t *rec_index, const dict_index_t *prebuilt_index,\n    const ulint *offsets, ulint field_no, const mysql_row_templ_t *templ,\n    ulint sec_field_no, lob::undo_vers_t *lob_undo, mem_heap_t *&blob_heap) {\n  DBUG_TRACE;\n  ...\n    } else {\n    /* Field is stored in the row. */\n\n    data = rec_get_nth_field_instant(rec, offsets, field_no, index_used, &len);\n\n    if (len == UNIV_SQL_NULL) {\n      /* MySQL assumes that the field for an SQL\n      NULL value is set to the default value. */\n      ut_ad(templ->mysql_null_bit_mask);\n\n      UNIV_MEM_ASSERT_RW(prebuilt->default_rec + templ->mysql_col_offset,\n                         templ->mysql_col_len);\n      mysql_rec[templ->mysql_null_byte_offset] |=\n          (byte)templ->mysql_null_bit_mask;\n      memcpy(mysql_rec + templ->mysql_col_offset,\n             (const byte *)prebuilt->default_rec + templ->mysql_col_offset,\n             templ->mysql_col_len);\n      return true;\n    } \n\n    if (DATA_LARGE_MTYPE(templ->type) || DATA_GEOMETRY_MTYPE(templ->type)) {\n      ...\n      mem_heap_t *heap{};\n\n      if (blob_heap == nullptr) {\n        blob_heap = mem_heap_create(UNIV_PAGE_SIZE, UT_LOCATION_HERE);\n      } \n\n      heap = blob_heap;\n      data = static_cast<byte *>(mem_heap_dup(heap, data, len));\n    } \n\n    /* Reassign the clustered index field no. */\n    if (clust_templ_for_sec) {\n      field_no = clust_field_no;\n    } \n\n    row_sel_field_store_in_mysql_format(mysql_rec + templ->mysql_col_offset,\n                                        templ, rec_index, field_no, data, len,\n                                        sec_field_no);\n    ... \n```", "```cpp\n/** Convert a non-SQL-NULL field from Innobase format to MySQL format. */\nstatic inline void row_sel_field_store_in_mysql_format(\n    byte *dest, const mysql_row_templ_t *templ, const dict_index_t *idx,\n    ulint field, const byte *src, ulint len, ulint sec) {\n  row_sel_field_store_in_mysql_format_func(\n      dest, templ, idx, IF_DEBUG(field, ) src, len IF_DEBUG(, sec));\n} \n```", "```cpp\nvoid row_sel_field_store_in_mysql_format_func(\n    byte *dest, const mysql_row_templ_t *templ, const dict_index_t *index,\n    IF_DEBUG(ulint field_no, ) const byte *data,\n    ulint len IF_DEBUG(, ulint sec_field)) {\n  byte *ptr;\n\n  ...\n\n  if (templ->is_multi_val) {\n    ib::fatal(UT_LOCATION_HERE, ER_CONVERT_MULTI_VALUE)\n        << \"Table name: \" << index->table->name\n        << \" Index name: \" << index->name;\n  } \n```", "```cpp\ncommit ffe1726f2542505e486c4bcd516c30f36c8ed5f6 (HEAD)\nAuthor: Knut Anders Hatlen <knut.hatlen@oracle.com>\nDate:   Wed Dec 21 14:29:02 2022 +0100\n\n    Bug#34891365: MySQL 8.0.29+ is slower than MySQL 8.0.28 with\n    queries using JOINS\n\n    The one-row cache in EQRefIterator was disabled for queries using\n    streaming aggregation in the fix for bug#33674441. This was done in\n    order to fix a number of wrong result bugs, but it turned out to have\n    too big impact on the performance of many queries.\n\n    This patch re-enables the cache for the above queries, and fixes the\n    original wrong result bugs in a different way. There were two\n    underlying problems that caused the wrong results:\n\n    1) AggregateIterator::Init() does not restore the table buffers to the\n    state they had after the last read from the child iterator in the\n    previous invocation. The table buffers would have the content from the\n    first row in the last group that was returned from the iterator in the\n    previous invocation, rather than the contents of the last row read by\n    the child iterator, and this made the cache in EQRefIterator return\n    wrong values. Fixed by restoring the table buffers in\n    AggregateIterator::Init() if the previous invocation had modified\n    them.\n\n    2) When the inner tables of an outer join are null-complemented, the\n    table buffers are modified to contain NULL values, thereby disturbing\n    the cached value for any EQRefIterator reading from one of the\n    null-complemented tables. Fixed by making StoreFromTableBuffers()\n    store the actual values contained in the table buffer instead of the\n    null values, if the table is accessed by EQRefIterator.\n    LoadIntoTableBuffers() is taught to restore those values, but\n    additionally set the null flags on the columns after restoring them.\n\n    The hypergraph optimizer had another workaround for these wrong\n    results (it added a streaming step right before the aggregation). This\n    workaround is also removed now.\n\n    Change-Id: I554a90213cae60749dd6407e48a745bc71578e0c \n```"]