- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 5. The Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 1 What is a process?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are all familiar with the modern operating system running many tasks all
    at once or *multitasking*.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of each process as a bundle of elements kept by the kernel to keep
    track of all these running tasks.
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 2 Elements of a process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <picture>![The essential elements of a process; the process ID, memory, files
    and registers.](theprocess.svg)</picture>Figure 2.1 The Elements of a Process
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Process ID
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *process ID* (or the PID) is assigned by the operating system and is unique
    to each running process.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Memory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will learn exactly how a process gets its memory in the following weeks --
    it is one of the most fundamental parts of how the operating system works. However,
    for now it is sufficient to know that each process gets its own section of memory.
  prefs: []
  type: TYPE_NORMAL
- en: In this memory all the program code is stored, along with variables and any
    other allocated storage.
  prefs: []
  type: TYPE_NORMAL
- en: Parts of the memory can be shared between processes (called, not surprisingly
    *shared memory*). You will often see this called *System Five Shared Memory* (or
    SysV SHM) after the original implementation in an older operating system.
  prefs: []
  type: TYPE_NORMAL
- en: Another important concept a process may utilise is that of *mmap*ing a file
    on disk to memory. This means that instead of having to open the file and use
    commands such as `read()` and `write()` the file looks as if it were any other
    type of RAM. `mmaped` areas have permissions such as read, write and execute which
    need to be kept track of. As we know, it is the job of the operating system to
    maintain security and stability, so it needs to check if a process tries to write
    to a read only area and return an error.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Code and Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A process can be further divided into *code* and `data` sections. Program code
    and data should be kept separately since they require different permissions from
    the operating system and separation facilitates sharing of code (as you see later).
    The operating system needs to give program code permission to be read and executed,
    but generally not written to. On the other hand data (variables) require read
    and write permissions but should not be executableNot all architectures support
    this, however. This has lead to a wide range of security problems on many architectures..
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 The Stack
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One other very important part of a process is an area of memory called *the
    stack*. This can be considered part of the data section of a process, and is intimately
    involved in the execution of any program.
  prefs: []
  type: TYPE_NORMAL
- en: A stack is generic data structure that works exactly like a stack of plates;
    you can *push* an item (put a plate on top of a stack of plates), which then becomes
    the top item, or you can *pop* an item (take a plate off, exposing the previous
    plate).
  prefs: []
  type: TYPE_NORMAL
- en: Stacks are fundamental to function calls. Each time a function is called it
    gets a new `stack frame`. This is an area of memory which usually contains, at
    a minimum, the address to return to when complete, the input arguments to the
    function and space for local variables.
  prefs: []
  type: TYPE_NORMAL
- en: By convention, stacks usually *grow down*Some architectures, such as PA-RISC
    from HP, have stacks that grow upwards. On some other architectures, such as IA64,
    there are other storage areas (the register backing store) that grow from the
    bottom toward the stack. . This means that the stack starts at a high address
    in memory and progressively gets lower.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![How the stack works with function calls. Note that the stack grows
    downwards, from high addresses in memory to low addresses.](stack.svg)</picture>Figure 2.2.2.1 The
    Stack
  prefs: []
  type: TYPE_NORMAL
- en: We can see how having a stack brings about many of the features of functions.
  prefs: []
  type: TYPE_NORMAL
- en: Each function has its own copy of its input arguments. This is because each
    function is allocated a new stack frame with its arguments in a fresh area of
    memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the reason why a variable defined inside a function can not be seen
    by other functions. Global variables (which can be seen by any function) are kept
    in a separate area of data memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This facilitates *recursive* calls. This means a function is free to call itself
    again, because a new stack frame will be created for all its local variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each frame contains the address to return to. C only allows a single value to
    be returned from a function, so by convention this value is returned to the calling
    function in a specified register, rather than on the stack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because each frame has a reference to the one before it, a debugger can "walk"
    backwards, following the pointers up the stack. From this it can produce a *stack
    trace* which shows you all functions that were called leading into this function.
    This is extremely useful for debugging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see how the way functions works fits exactly into the nature of a stack.
    Any function can call any other function, which then becomes the up most function
    (put on top of the stack). Eventually that function will return to the function
    that called it (takes itself off the stack).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Stacks do make calling functions slower, because values must be moved out of
    registers and into memory. Some architectures allow arguments to be passed in
    registers directly; however to keep the semantics that each function gets a unique
    copy of each argument the registers must *rotate*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may have heard of the term a *stack overflow*. This is a common way of hacking
    a system by passing bogus values. If you as a programmer accept arbitrary input
    into a stack variable (say, reading from the keyboard or over the network) you
    need to explicitly say how big that data is going to be.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allowing any amount of data unchecked will simply overwrite memory. Generally
    this leads to a crash, but some people realised that if they overwrote just enough
    memory to place a specific value in the return address part of the stack frame,
    when the function completed rather than returning to the correct place (where
    it was called from) they could make it return into the data they just sent. If
    that data contains binary executable code that hacks the system (e.g. starts a
    terminal for the user with root privileges) then your computer has been compromised.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This happens because the stack grows downwards, but data is read in "upwards"
    (i.e. from lower address to higher addresses).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There are several ways around this; firstly as a programmer you must ensure
    that you always check the amount of data you are receiving into a variable. The
    operating system can help to avoid this on behalf of the programmer by ensuring
    that the stack is marked as *not executable*; that is that the processor will
    not run any code, even if a malicious user tries to pass some into your program.
    Modern architectures and operating systems support this functionality.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Stacks are ultimately managed by the compiler, as it is responsible for generating
    the program code. To the operating system the stack just looks like any other
    area of memory for the process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To keep track of the current growth of the stack, the hardware defines a register
    as the *stack pointer*. The compiler (or the programmer, when writing in assembler)
    uses this register to keep track of the current top of the stack.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Example 2.2.2.1 Stack pointer example
  prefs: []
  type: TYPE_NORMAL
- en: Above we show a simple function allocating three variables on the stack. The
    disassembly illustrates the use of the stack pointer on the x86 architectureNote
    we used the special flag to gcc `-fomit-frame-pointer` which specifies that an
    extra register should *not* be used to keep a pointer to the start of the stack
    frame. Having this pointer helps debuggers to walk upwards through the stack frames,
    however it makes one less register available for other applications.. Firstly
    we allocate some space on the stack for our local variables. Since the stack grows
    down, we subtract from the value held in the stack pointer. The value 16 is a
    value large enough to hold our local variables, but may not be exactly the size
    required (for example with 3 4 byte `int` values we really only need 12 bytes,
    not 16) to keep alignment of the stack in memory on certain boundaries as the
    compiler requires.
  prefs: []
  type: TYPE_NORMAL
- en: Then we move the values into the stack memory (and in a real function, use them).
    Finally, before returning to our parent function we "pop" the values off the stack
    by moving the stack pointer back to where it was before we started.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3 The Heap
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The heap is an area of memory that is managed by the process for on the fly
    memory allocation. This is for variables whose memory requirements are not known
    at compile time.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom of the heap is known as the *brk*, so called for the system call
    which modifies it. By using the `brk` call to grow the area downwards the process
    can request the kernel allocate more memory for it to use.
  prefs: []
  type: TYPE_NORMAL
- en: The heap is most commonly managed by the `malloc` library call. This makes managing
    the heap easy for the programmer by allowing them to simply allocate and free
    (via the `free` call) heap memory. `malloc` can use schemes like a *buddy allocator*
    to manage the heap memory for the user. `malloc` can also be smarter about allocation
    and potentially use *anonymous mmaps* for extra process memory. This is where
    instead of mmaping a *file* into the process memory it directly maps an area of
    system RAM. This can be more efficient. Due to the complexity of managing memory
    correctly, it is very uncommon for any modern program to have a reason to call
    `brk` directly.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.4 Memory Layout
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: <picture>![A sample of how process memory is allocated.](memory-layout.svg)</picture>Figure 2.2.4.1 Process
    memory layout
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen a process has smaller areas of memory allocated to it, each
    with a specific purpose.
  prefs: []
  type: TYPE_NORMAL
- en: An example of how the process is laid out in memory by the kernel is given above.
    Starting from the top, the kernel reserves itself some memory at the top of the
    process (we see with virtual memory how this memory is actually shared between
    all processes).
  prefs: []
  type: TYPE_NORMAL
- en: Underneath that is room for `mmaped` files and libraries. Underneath that is
    the stack, and below that the heap.
  prefs: []
  type: TYPE_NORMAL
- en: At the bottom is the program image, as loaded from the executable file on disk.
    We take a closer look at the process of loading this data in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 File Descriptors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the first week we learnt about `stdin`, `stdout` and `stderr`; the default
    files given to each process. You will remember that these files always have the
    same file descriptor number (0,1,2 respectively).
  prefs: []
  type: TYPE_NORMAL
- en: Thus, file descriptors are kept by the kernel individually for each process.
  prefs: []
  type: TYPE_NORMAL
- en: File descriptors also have permissions. For example, you may be able to read
    from a file but not write to it. When the file is opened, the operating system
    keeps a record of the processes permissions to that file in the file descriptor
    and doesn't allow the process to do anything it shouldn't.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Registers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We know from the previous chapter that the processor essentially performs generally
    simple operations on values in registers. These values are read (and written)
    to memory -- we mentioned above that each process is allocated memory which the
    kernel keeps track of.
  prefs: []
  type: TYPE_NORMAL
- en: So the other side of the equation is keeping track of the registers. When it
    comes time for the currently running process to give up the processor so another
    process can run, it needs to save its current state. Equally, we need to be able
    to restore this state when the process is given more time to run on the CPU. To
    do this the operating system needs to store a copy of the CPU registers to memory.
    When it is time for the process to run again, the operating system will copy the
    register values back from memory to the CPU registers and the process will be
    right back where it left off.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Kernel State
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Internally, the kernel needs to keep track of a number of elements for each
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.1 Process State
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another important element for the operating system to keep track of is the process
    state. If the process is currently running it makes sense to have it in a *running*
    state.
  prefs: []
  type: TYPE_NORMAL
- en: However, if the process has requested to read a file from disk we know from
    our memory hierarchy that this may take a significant amount of time. The process
    should give up its current execution to allow another process to run, but the
    kernel need not let the process run again until the data from the disk is available
    in memory. Thus it can mark the process as *disk wait* (or similar) until the
    data is ready.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.2 Priority
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Some processes are more important than others, and get a higher priority. See
    the discussion on the scheduler below.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.3 Statistics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The kernel can keep statistics on each processes behaviour which can help it
    make decisions about how the process behaves; for example does it mostly read
    from disk or does it mostly do CPU intensive operations?
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 3 Process Hierarchy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whilst the operating system can run many processes at the same time, in fact
    it only ever directly starts one process called the *init* (short for initial)
    process. This isn't a particularly special process except that its PID is always
    0 and it will *always* be running.
  prefs: []
  type: TYPE_NORMAL
- en: All other processes can be considered *children* of this initial process. Processes
    have a family tree just like any other; each process has a *parent* and can have
    many *siblings*, which are processes createdThe term *spawn* is often used when
    talking about parent processes creating children; as in "the process spawned a
    child". by the same parent.
  prefs: []
  type: TYPE_NORMAL
- en: Certainly children can create more children and so on and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Example 3.1 `pstree` example</main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 4 Fork and Exec
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: New processes are created by the two related interfaces `fork` and `exec`.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Fork
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When you come to metaphorical "fork in the road" you generally have two options
    to take, and your decision effects your future. Computer programs reach this fork
    in the road when they hit the `fork()` system call.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the operating system will create a new process that is exactly
    the same as the parent process. This means all the state that was talked about
    previously is copied, including open files, register state and all memory allocations,
    which includes the program code.
  prefs: []
  type: TYPE_NORMAL
- en: The return value from the system call is the only way the process can determine
    if it was the existing process or a new one. The return value to the parent process
    will be the Process ID (PID) of the child, whilst the child will get a return
    value of 0.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we say the process has `forked` and we have the parent-child
    relationship as described above.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Exec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Forking provides a way for an existing process to start a new one, but what
    about the case where the new process is not part of the same program as parent
    process? This is the case in the shell; when a user starts a command it needs
    to run in a new process, but it is unrelated to the shell.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the `exec` system call comes into play. `exec` will *replace*
    the contents of the currently running process with the information from a program
    binary.
  prefs: []
  type: TYPE_NORMAL
- en: Thus the process the shell follows when launching a new program is to firstly
    `fork`, creating a new process, and then `exec` (i.e. load into memory and execute)
    the program binary it is supposed to run.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 How Linux actually handles fork and exec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 4.3.1  `clone`
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the kernel, fork is actually implemented by a `clone` system call. This `clone`
    interfaces effectively provides a level of abstraction in how the Linux kernel
    can create processes.
  prefs: []
  type: TYPE_NORMAL
- en: '`clone` allows you to explicitly specify which parts of the new process are
    copied into the new process, and which parts are shared between the two processes.
    This may seem a bit strange at first, but allows us to easily implement *threads*
    with one very simple interface.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1.1 Threads
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While `fork` copies all of the attributes we mentioned above, imagine if everything
    was copied for the new process *except* for the memory. This means the parent
    and child share the same memory, which includes program code and data.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![The memory (including program code and variables) of the process
    are shared by the threads, but each has its own kernel state, so they can be running
    different parts of the code at the same time.](threads.svg)</picture>Figure 4.3.1.1.1 Threads
  prefs: []
  type: TYPE_NORMAL
- en: This hybrid child is called a *thread*. Threads have a number of advantages
    over where you might use *fork*
  prefs: []
  type: TYPE_NORMAL
- en: Separate processes can not see each others memory. They can only communicate
    with each other via other system calls.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Threads however, share the same memory. So you have the advantage of multiple
    processes, with the expense of having to use system calls to communicate between
    them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The problem that this raises is that threads can very easily step on each others
    toes. One thread might increment a variable, and another may decrease it without
    informing the first thread. These type of problems are called *concurrency problems*
    and they are many and varied.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To help with this, there are userspace libraries that help programmers work
    with threads properly. The most common one is called `POSIX threads` or, as it
    more commonly referred to `pthreads`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Switching processes is quite expensive, and one of the major expenses is keeping
    track of what memory each process is using. By sharing the memory this overhead
    is avoided and performance can be significantly increased.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are many different ways to implement threads. On the one hand, a userspace
    implementation could implement threads within a process without the kernel having
    any idea about it. The threads all look like they are running in a single process
    to the kernel.
  prefs: []
  type: TYPE_NORMAL
- en: This is suboptimal mainly because the kernel is being withheld information about
    what is running in the system. It is the kernels job to make sure that the system
    resources are utilised in the best way possible, and if what the kernel thinks
    is a single process is actually running multiple threads it may make suboptimal
    decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Thus the other method is that the kernel has full knowledge of the thread. Under
    Linux, this is established by making all processes able to share resources via
    the `clone` system call. Each thread still has associated kernel resources, so
    the kernel can take it into account when doing resource allocations.
  prefs: []
  type: TYPE_NORMAL
- en: Other operating systems have a hybrid method, where some threads can be specified
    to run in userspace only ("hidden" from the kernel) and others might be a *light
    weight process*, a similar indication to the kernel that the processes is part
    of a thread group.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1.2 Copy on write
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As we mentioned, copying the entire memory of one process to another when `fork`
    is called is an expensive operation.
  prefs: []
  type: TYPE_NORMAL
- en: One optimisation is called *copy on write*. This means that similar to threads
    above, the memory is actually shared, rather than copied, between the two processes
    when fork is called. If the processes are only going to be reading the memory,
    then actually copying the data is unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: However, when a process writes to its memory, it needs to be a private copy
    that is not shared. As the name suggests, copy on write optimises this by only
    doing the actual copy of the memory at the point when it is written to.
  prefs: []
  type: TYPE_NORMAL
- en: Copy on write also has a big advantage for `exec`. Since `exec` will simply
    be overwriting all the memory with the new program, actually copying the memory
    would waste a lot of time. Copy on write saves us actually doing the copy.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 The init process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We discussed the overall goal of the init process previously, and we are now
    in a position to understand how it works.
  prefs: []
  type: TYPE_NORMAL
- en: On boot the kernel starts the init process, which then forks and execs the systems
    boot scripts. These fork and exec more programs, eventually ending up forking
    a login process.
  prefs: []
  type: TYPE_NORMAL
- en: The other job of the `init` process is "reaping". When a process calls `exit`
    with a return code, the parent usually wants to check this code to see if the
    child exited correctly or not.
  prefs: []
  type: TYPE_NORMAL
- en: However, this exit code is part of the process which has just called `exit`.
    So the process is "dead" (e.g. not running) but still needs to stay around until
    the return code is collected. A process in this state is called a *zombie* (the
    traits of which you can contrast with a mystical zombie!)
  prefs: []
  type: TYPE_NORMAL
- en: A process stays as a zombie until the parent collects the return code with the
    `wait` call. However, if the parent exits before collecting this return code,
    the zombie process is still around, waiting aimlessly to give its status to someone.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the zombie child will be *reparented* to the init process which
    has a special handler that *reaps* the return value. Thus the process is finally
    free and the descriptor can be removed from the kernels process table.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.1 Zombie example
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Example 4.4.1.1 Zombie example process
  prefs: []
  type: TYPE_NORMAL
- en: Above we create a zombie process. The parent process will sleep forever, whilst
    the child will exit after a few seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Below the code you can see the results of running the program. The parent process
    (16168) is in state `S` for sleep (as we expect) and the child is in state `Z`
    for zombie. The ps output also tells us that the process is `defunct` in the process
    description.The square brackets around the "z" of "zombie" are a little trick
    to remove the grep processes itself from the ps output. grep interprets everything
    between the square brackets as a character class, but because the process name
    will be "grep [z]ombie" (with the brackets) this will not match!
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 5 Context Switching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Context switching refers to the process the kernel undertakes to switch from
    one process to another. XXX ?
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 6 Scheduling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A running system has many processes, maybe even into the hundreds or thousands.
    The part of the kernel that keeps track of all these processes is called the *scheduler*
    because it schedules which process should be run next.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling algorithms are many and varied. Most users have different goals relating
    to what they want their computer to do, so this affects scheduling decisions.
    For example, for a desktop PC you want to make sure that your graphical applications
    for your desktop are given plenty of time to run, even if system processes take
    a little longer. This will increase the responsiveness the user feels, as their
    actions will have more immediate responses. For a server, you might want your
    web server application to be given priority.
  prefs: []
  type: TYPE_NORMAL
- en: People are always coming up with new algorithms, and you can probably think
    of your own fairly easily. But there are a number of different components of scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Preemptive v co-operative scheduling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Scheduling strategies can broadly fall into two categories
  prefs: []
  type: TYPE_NORMAL
- en: '*Co-operative* scheduling is where the currently running process voluntarily
    gives up executing to allow another process to run. The obvious disadvantage of
    this is that the process may decide to never give up execution, probably because
    of a bug causing some form of infinite loop, and consequently nothing else can
    ever run.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Preemptive* scheduling is where the process is interrupted to stop it to allow
    another process to run. Each process gets a *time-slice* to run in; at the point
    of each context switch a timer will be reset and will deliver and interrupt when
    the time-slice is over.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We know that the hardware handles the interrupt independently of the running
    process, and so at this point control will return to the operating system. At
    this point, the scheduler can decide which process to run next.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the type of scheduling used by all modern operating systems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 6.2 Realtime
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some processes need to know exactly how long their time-slice will be, and how
    long it will be before they get another time-slice to run. Say you have a system
    running a heart-lung machine; you don't want the next pulse to be delayed because
    something else decided to run in the system!
  prefs: []
  type: TYPE_NORMAL
- en: Hard realtime systems make guarantees about scheduling decisions like the maximum
    amount of time a process will be interrupted before it can run again. They are
    often used in life critical applications like medical, aircraft and military applications.
  prefs: []
  type: TYPE_NORMAL
- en: Soft realtime is a variation on this, where guarantees aren't as strict but
    general system behaviour is predictable. Linux can be used like this, and it is
    often used in systems dealing with audio and video. If you are recording an audio
    stream, you don't want to be interrupted for long periods of time as you will
    loose audio data which can not be retrieved.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Nice value
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: UNIX systems assign each process a *nice* value. The scheduler looks at the
    nice value and can give priority to those processes that have a higher "niceness".
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 A brief look at the Linux Scheduler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Linux scheduler has and is constantly undergoing many changes as new developers
    attempt to improve its behaviour.
  prefs: []
  type: TYPE_NORMAL
- en: The current scheduler is known as the O(1) scheduler, which refers to the property
    that no matter how many processes the scheduler has to choose from, it will choose
    the next one to run in a constant amount of time*Big-O* notation is a way of describing
    how long an algorithm takes to run given increasing inputs. If the algorithm takes
    twice as long to run for twice as much input, this is increasing linearly. If
    another algorithm takes four times as long to run given twice as much input, then
    it is increasing exponentially. Finally if it takes the same amount of time now
    matter how much input, then the algorithm runs in constant time. Intuitively you
    can see that the slower the algorithm grows for more input, the better it is.
    Computer science text books deal with algorithm analysis in more detail..
  prefs: []
  type: TYPE_NORMAL
- en: Previous incarnations of the Linux scheduler used the concept of *goodness*
    to determine which process to run next. All possible tasks are kept on a *run
    queue*, which is simply a linked list of processes which the kernel knows are
    in a "runnable" state (i.e. not waiting on disk activity or otherwise asleep).
    The problem arises that to calculate the next process to run, every possible runnable
    process must have its goodness calculated and the one with the highest goodness
    ``wins''. You can see that for more tasks, it will take longer and longer to decide
    which processes will run next.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![A view of how the Linux scheduler manages processes.](o1queue.svg)</picture>Figure 6.4.1 The
    O(1) scheduler
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the O(1) scheduler uses a run queue structure as shown above. The
    run queue has a number of *buckets* in priority order and a bitmap that flags
    which buckets have processes available. Finding the next process to run is a matter
    of reading the bitmap to find the first bucket with processes, then picking the
    first process off that bucket's queue. The scheduler keeps two such structures,
    an *active* and *expired* array for processes that are runnable and those which
    have utilised their entire time slice respectively. These can be swapped by simply
    modifying pointers when all processes have had some CPU time.
  prefs: []
  type: TYPE_NORMAL
- en: The really interesting part, however, is how it is decided where in the run
    queue a process should go. Some of the things that need to be taken into account
    are the nice level, processor affinity (keeping processes tied to the processor
    they are running on, since moving a process to another CPU in a SMP system can
    be an expensive operation) and better support for identifying interactive programs
    (applications such as a GUI which may spend much time sleeping, waiting for user
    input, but when the user *does* get around to interacting with it wants a fast
    response).
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 7 The Shell
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On a UNIX system, the shell is the standard interface to handling processes
    on your system. Once the shell was the primary interface, however modern Linux
    systems have a GUI and provide a shell via a "terminal application" or similar.
    The primary job of the shell is to help the user handle starting, stopping and
    otherwise controlling processes running in the system.
  prefs: []
  type: TYPE_NORMAL
- en: When you type a command at the prompt of the shell, it will `fork` a copy of
    itself and `exec` the command that you have specified.
  prefs: []
  type: TYPE_NORMAL
- en: The shell then, by default, waits for that process to finish running before
    returning to a prompt to start the whole process over again.
  prefs: []
  type: TYPE_NORMAL
- en: As an enhancement, the shell also allows you to *background* a job, usually
    by placing an `&` after the command name. This is simply a signal that the shell
    should fork and execute the command, but *not* wait for the command to complete
    before showing you the prompt again.
  prefs: []
  type: TYPE_NORMAL
- en: The new process runs in the background, and the shell is ready waiting to start
    a new process should you desire. You can usually tell the shell to *foreground*
    a process, which means we do actually want to wait for it to finish.
  prefs: []
  type: TYPE_NORMAL
- en: 'XXX : a bit of history about bourne shell'
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
- en: <main class="calibre3">
  prefs: []
  type: TYPE_NORMAL
- en: 8 Signals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Processes running in the system require a way to be told about events that influence
    them. On UNIX there is infrastructure between the kernel and processes called
    *signals* which allows a process to receive notification about events important
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: When a signal is sent to a process, the kernel invokes a *handler* which the
    process must register with the kernel to deal with that signal. A handler is simply
    a designed function in the code that has been written to specifically deal with
    interrupt. Often the signal will be sent from inside the kernel itself, however
    it is also common for one process to send a signal to another process (one form
    of *interprocess communication*). The signal handler gets called *asynchronously*;
    that is the currently running program is interrupted from what it is doing to
    process the signal event.
  prefs: []
  type: TYPE_NORMAL
- en: For example, one type of signal is an *interrupt* (defined in system headers
    as `SIGINT`) is delivered to the process when the `ctrl-c` combination is pressed.
  prefs: []
  type: TYPE_NORMAL
- en: As a process uses the `read` system call to read input from the keyboard, the
    kernel will be watching the input stream looking for special characters. Should
    it see a `ctrl-c` it will jump into signal handling mode. The kernel will look
    to see if the process has registered a handler for this interrupt. If it has,
    then execution will be passed to that function where the function will *handle*
    it. Should the process have not registered a handler for this particular signal,
    then the kernel will take some default action. With `ctrl-c` the default action
    is to terminate the process.
  prefs: []
  type: TYPE_NORMAL
- en: A process can choose to ignore some signals, but other signals are not allowed
    to be ignored. For example, `SIGKILL` is the signal sent when a process should
    be terminated. The kernel will see that the process has been sent this signal
    and terminate the process from running, no questions asked. The process can not
    ask the kernel to ignore this signal, and the kernel is very careful about which
    process is allowed to send this signal to another process; you may only send it
    to processes owned by you unless you are the root user. You may have seen the
    command `kill -9`; this comes from the implementation `SIGKILL` signal. It is
    commonly known that `SIGKILL` is actually defined to be `0x9`, and so when specified
    as an argument to the `kill` program means that the process specified is going
    to be stopped immediately. Since the process can not choose to ignore or handle
    this signal, it is seen as an avenue of last resort, since the program will have
    no chance to clean up or exit cleanly. It is considered better to first send a
    `SIGTERM` (for terminate) to the process first, and if it has crashed or otherwise
    will not exit then resort to the `SIGKILL`. As a matter of convention, most programs
    will install a handler for `SIGHUP` (hangup -- a left over from days of serial
    terminals and modems) which will reload the program, perhaps to pick up changes
    in a configuration file or similar.
  prefs: []
  type: TYPE_NORMAL
- en: If you have programmed on a Unix system you would be familiar with `segmentation
    faults` when you try to read or write to memory that has not been allocated to
    you. When the kernel notices that you are touching memory outside your allocation,
    it will send you the segmentation fault signal. Usually the process will not have
    a handler installed for this, and so the default action to terminate the program
    ensues (hence your program "crashes"). In some cases a program may install a handler
    for segmentation faults, although reasons for doing this are limited.
  prefs: []
  type: TYPE_NORMAL
- en: This raises the question of what happens after the signal is received. Once
    the signal handler has finished running, control is returned to the process which
    continues on from where it left off.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The following simple program introduces a lot of signals to run!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Example 8.1.1 Signals Example
  prefs: []
  type: TYPE_NORMAL
- en: We have simple program that simply defines a handler for the `SIGINT` signal,
    which is sent when the user presses `ctrl-c`. All the signals for the system are
    defined in `signal.h`, including the `signal` function which allows us to register
    the handling function.
  prefs: []
  type: TYPE_NORMAL
- en: The program simply sits in a tight loop doing nothing until it quits. When we
    start the program, we try pressing `ctrl-c` to make it quit. Rather than taking
    the default action, or handler is invoked and we get the output as expected.
  prefs: []
  type: TYPE_NORMAL
- en: We then press `ctrl-z` which sends a `SIGSTOP` which by default puts the process
    to sleep. This means it is not put in the queue for the scheduler to run and is
    thus dormant in the system.
  prefs: []
  type: TYPE_NORMAL
- en: As an illustration, we use the kill program to send the same signal from another
    terminal window. This is actually implemented with the `kill` system call, which
    takes a signal and PID to send to (this function is a little misnamed because
    not all signals do actually kill the process, as we are seeing, but the `signal`
    function was already taken to register the handler). As the process is stopped,
    the signal gets *queued* for the process. This means the kernel takes note of
    the signal and will deliver it when appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: At this point we wake the process up by using the command `fg`. This actually
    sends a `SIGCONT` signal to the process, which by default will wake the process
    back up. The kernel knows to put the process on the run queue and give it CPU
    time again. We see at this point the queued signal is delivered.
  prefs: []
  type: TYPE_NORMAL
- en: In desperation to get rid of the program, we finally try `ctrl-\` which sends
    a `SIGQUIT` (abort) to the process. But if the process has aborted, where did
    the `Quit` output come from?
  prefs: []
  type: TYPE_NORMAL
- en: You guessed it, more signals! When a parent child has a process that dies, it
    gets a `SIGCHLD` signal back. In this case the shell was the parent process and
    so it got the signal. Remember how we have the zombie process that needs to be
    reaped with the `wait` call to get the return code from the child process? Well
    another thing it also gives the parent is the signal number that the child may
    have died from. Thus the shell knows that child process died from a `SIGABRT`
    and as an informational service prints as much for the user (the same process
    happens to print out "Segmentation Fault" when the child process dies from a `SIGSEGV`).
  prefs: []
  type: TYPE_NORMAL
- en: You can see how in even a simple program, around 5 different signals were used
    to communicate between processes and the kernel and keep things running. There
    are many other signals, but these are certainly amongst the most common. Most
    have system functions defined by the kernel, but there are a few signals reserved
    for users to use for their own purposes within their programs (`SIGUSR`).
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
